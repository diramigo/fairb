{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "import datalad.api as dl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainers_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcall_fmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Add a container to a dataset\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "name : str\n",
      "  The name to register the container under. This also determines the\n",
      "  default location of the container image within the dataset.\n",
      "url : str or None, optional\n",
      "  A URL (or local path) to get the container image from. If the URL\n",
      "  scheme is one recognized by Singularity ('shub://' or 'docker://'),\n",
      "  a command format string for Singularity-based execution will be\n",
      "  auto-configured when call_fmt is not specified. For Docker-based\n",
      "  container execution with the URL scheme 'dhub://', the rest of the\n",
      "  URL will be interpreted as the argument to 'docker pull', the image\n",
      "  will be saved to a location specified by `name`, and the call format\n",
      "  will be auto-configured to run docker, unless overwritten. [Default:\n",
      "  None]\n",
      "dataset : Dataset or None, optional\n",
      "  specify the dataset to add the container to. If no dataset is given,\n",
      "  an attempt is made to identify the dataset based on the current\n",
      "  working directory. [Default: None]\n",
      "call_fmt : str or None, optional\n",
      "  Command format string indicating how to execute a command in this\n",
      "  container, e.g. \"singularity exec {img} {cmd}\". Where '{img}' is a\n",
      "  placeholder for the path to the container image and '{cmd}' is\n",
      "  replaced with the desired command. Additional placeholders:\n",
      "  '{img_dspath}' is relative path to the dataset containing the image.\n",
      "  [Default: None]\n",
      "image : str or None, optional\n",
      "  Relative path of the container image within the dataset. If not\n",
      "  given, a default location will be determined using the `name`\n",
      "  argument. [Default: None]\n",
      "update : bool, optional\n",
      "  Update the existing container for `name`. If no other options are\n",
      "  specified, URL will be set to 'updateurl', if configured. If a\n",
      "  container with `name` does not already exist, this option is\n",
      "  ignored. [Default: False]\n",
      "on_failure : {'ignore', 'continue', 'stop'}, optional\n",
      "  behavior to perform on failure: 'ignore' any failure is reported,\n",
      "  but does not cause an exception; 'continue' if any failure occurs an\n",
      "  exception will be raised at the end, but processing other actions\n",
      "  will continue for as long as possible; 'stop': processing will stop\n",
      "  on first failure and an exception is raised. A failure is any result\n",
      "  with status 'impossible' or 'error'. Raised exception is an\n",
      "  IncompleteResultsError that carries the result dictionaries of the\n",
      "  failures in its `failed` attribute. [Default: 'continue']\n",
      "result_filter : callable or None, optional\n",
      "  if given, each to-be-returned status dictionary is passed to this\n",
      "  callable, and is only returned if the callable's return value does\n",
      "  not evaluate to False or a ValueError exception is raised. If the\n",
      "  given callable supports `**kwargs` it will additionally be passed\n",
      "  the keyword arguments of the original API call. [Default: None]\n",
      "result_renderer\n",
      "  select rendering mode command results. 'tailored' enables a command-\n",
      "  specific rendering style that is typically tailored to human\n",
      "  consumption, if there is one for a specific command, or otherwise\n",
      "  falls back on the the 'generic' result renderer; 'generic' renders\n",
      "  each result in one line  with key info like action, status, path,\n",
      "  and an optional message); 'json' a complete JSON line serialization\n",
      "  of the full result record; 'json_pp' like 'json', but pretty-printed\n",
      "  spanning multiple lines; 'disabled' turns off result rendering\n",
      "  entirely; '<template>' reports any value(s) of any result properties\n",
      "  in any format indicated by the template (e.g. '{path}', compare with\n",
      "  JSON output for all key-value choices). The template syntax follows\n",
      "  the Python \"format() language\". It is possible to report individual\n",
      "  dictionary values, e.g. '{metadata[name]}'. If a 2nd-level key\n",
      "  contains a colon, e.g. 'music:Genre', ':' must be substituted by '#'\n",
      "  in the template, like so: '{metadata[music#Genre]}'. [Default:\n",
      "  'tailored']\n",
      "result_xfm : {'datasets', 'successdatasets-or-none', 'paths', 'relpaths', 'metadata'} or callable or None, optional\n",
      "  if given, each to-be-returned result status dictionary is passed to\n",
      "  this callable, and its return value becomes the result instead. This\n",
      "  is different from `result_filter`, as it can perform arbitrary\n",
      "  transformation of the result value. This is mostly useful for top-\n",
      "  level command invocations that need to provide the results in a\n",
      "  particular format. Instead of a callable, a label for a pre-crafted\n",
      "  result transformation can be given. [Default: None]\n",
      "return_type : {'generator', 'list', 'item-or-list'}, optional\n",
      "  return value behavior switch. If 'item-or-list' a single value is\n",
      "  returned instead of a one-item return value list, or a list in case\n",
      "  of multiple return values. `None` is return in case of an empty\n",
      "  list. [Default: 'list']\n",
      "\u001b[0;31mFile:\u001b[0m      /misc/geminis/ramirezd/miniconda3/envs/py-minis/lib/python3.11/site-packages/datalad_container/containers_add.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "?dl.containers_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_vals = 'subject == sub-001A sub-001B ; voi == acc pcc * subject'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"<!glob>(inputs/mri-raw/sub-*/anat/*T1w.nii.gz)<!regex>(sub-\\w+)<!unique>\"\n",
    "vals = pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<glob>(inputs/mri-raw/sub-*/anat/*T1w.nii.gz)<regex>()'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(x):\n",
    "    try:\n",
    "        int(x)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def try_search(regex, val):\n",
    "    try:\n",
    "        return re.search(regex, val).group()\n",
    "    except:\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-001A',\n",
       " 'sub-001B',\n",
       " 'sub-002A',\n",
       " 'sub-002B',\n",
       " 'sub-003A',\n",
       " 'sub-003B',\n",
       " 'sub-004A',\n",
       " 'sub-004B',\n",
       " 'sub-005A',\n",
       " 'sub-005B',\n",
       " 'sub-006A',\n",
       " 'sub-006B',\n",
       " 'sub-007A',\n",
       " 'sub-007B',\n",
       " 'sub-008A',\n",
       " 'sub-008B',\n",
       " 'sub-009A',\n",
       " 'sub-009B',\n",
       " 'sub-010A',\n",
       " 'sub-010B',\n",
       " 'sub-010C',\n",
       " 'sub-011A',\n",
       " 'sub-011B',\n",
       " 'sub-012A',\n",
       " 'sub-012B',\n",
       " 'sub-013A',\n",
       " 'sub-013B',\n",
       " 'sub-014A',\n",
       " 'sub-014B',\n",
       " 'sub-015A',\n",
       " 'sub-015B',\n",
       " 'sub-016A',\n",
       " 'sub-016B',\n",
       " 'sub-017A',\n",
       " 'sub-017B',\n",
       " 'sub-018A',\n",
       " 'sub-018B',\n",
       " 'sub-019A',\n",
       " 'sub-019B',\n",
       " 'sub-020A',\n",
       " 'sub-020B',\n",
       " 'sub-021A',\n",
       " 'sub-021B',\n",
       " 'sub-022A',\n",
       " 'sub-022B',\n",
       " 'sub-023A',\n",
       " 'sub-023B',\n",
       " 'sub-024A',\n",
       " 'sub-024B',\n",
       " 'sub-025A',\n",
       " 'sub-025B',\n",
       " 'sub-026A',\n",
       " 'sub-026B',\n",
       " 'sub-027A',\n",
       " 'sub-027B',\n",
       " 'sub-028A',\n",
       " 'sub-028B',\n",
       " 'sub-029A',\n",
       " 'sub-029B',\n",
       " 'sub-030A',\n",
       " 'sub-030B',\n",
       " 'sub-031A',\n",
       " 'sub-031B',\n",
       " 'sub-032A',\n",
       " 'sub-032B',\n",
       " 'sub-033A',\n",
       " 'sub-033B',\n",
       " 'sub-034A',\n",
       " 'sub-034B',\n",
       " 'sub-035A',\n",
       " 'sub-035B',\n",
       " 'sub-036A',\n",
       " 'sub-036B',\n",
       " 'sub-037A',\n",
       " 'sub-037B',\n",
       " 'sub-038A',\n",
       " 'sub-038B',\n",
       " 'sub-039A',\n",
       " 'sub-039B',\n",
       " 'sub-040A',\n",
       " 'sub-040B',\n",
       " 'sub-041A',\n",
       " 'sub-041B',\n",
       " 'sub-042A',\n",
       " 'sub-042B',\n",
       " 'sub-043A',\n",
       " 'sub-043B',\n",
       " 'sub-044A',\n",
       " 'sub-044B',\n",
       " 'sub-045A',\n",
       " 'sub-045B',\n",
       " 'sub-046A',\n",
       " 'sub-046B',\n",
       " 'sub-047A',\n",
       " 'sub-047B',\n",
       " 'sub-048A',\n",
       " 'sub-048B',\n",
       " 'sub-049A',\n",
       " 'sub-049B',\n",
       " 'sub-050A',\n",
       " 'sub-050B',\n",
       " 'sub-051A',\n",
       " 'sub-051B',\n",
       " 'sub-052A',\n",
       " 'sub-052B',\n",
       " 'sub-053A',\n",
       " 'sub-053B',\n",
       " 'sub-054A',\n",
       " 'sub-054B',\n",
       " 'sub-055A',\n",
       " 'sub-055B',\n",
       " 'sub-056A',\n",
       " 'sub-056B',\n",
       " 'sub-057A',\n",
       " 'sub-057B',\n",
       " 'sub-058A',\n",
       " 'sub-058B',\n",
       " 'sub-059A',\n",
       " 'sub-059B',\n",
       " 'sub-060A',\n",
       " 'sub-060B',\n",
       " 'sub-061A',\n",
       " 'sub-061B',\n",
       " 'sub-062A',\n",
       " 'sub-062B',\n",
       " 'sub-063A',\n",
       " 'sub-063B',\n",
       " 'sub-064A',\n",
       " 'sub-064B',\n",
       " 'sub-065A',\n",
       " 'sub-065B',\n",
       " 'sub-066A',\n",
       " 'sub-066B',\n",
       " 'sub-067A',\n",
       " 'sub-067B',\n",
       " 'sub-068A',\n",
       " 'sub-068B',\n",
       " 'sub-069A',\n",
       " 'sub-069B',\n",
       " 'sub-070A',\n",
       " 'sub-070B',\n",
       " 'sub-071A',\n",
       " 'sub-071B',\n",
       " 'sub-072A',\n",
       " 'sub-072B',\n",
       " 'sub-073A',\n",
       " 'sub-073B',\n",
       " 'sub-074A',\n",
       " 'sub-074B',\n",
       " 'sub-075A',\n",
       " 'sub-075B',\n",
       " 'sub-076A',\n",
       " 'sub-076B',\n",
       " 'sub-077A',\n",
       " 'sub-077B',\n",
       " 'sub-078A',\n",
       " 'sub-078B',\n",
       " 'sub-079A',\n",
       " 'sub-079B',\n",
       " 'sub-080A',\n",
       " 'sub-080B',\n",
       " 'sub-081A',\n",
       " 'sub-081B',\n",
       " 'sub-082A',\n",
       " 'sub-082B',\n",
       " 'sub-083A',\n",
       " 'sub-083B',\n",
       " 'sub-084A',\n",
       " 'sub-084B',\n",
       " 'sub-085A',\n",
       " 'sub-085B',\n",
       " 'sub-086A',\n",
       " 'sub-086B',\n",
       " 'sub-087A',\n",
       " 'sub-087B',\n",
       " 'sub-088A',\n",
       " 'sub-089A',\n",
       " 'sub-089B',\n",
       " 'sub-090A',\n",
       " 'sub-090B',\n",
       " 'sub-091A',\n",
       " 'sub-091B',\n",
       " 'sub-092A',\n",
       " 'sub-092B',\n",
       " 'sub-093A',\n",
       " 'sub-093B',\n",
       " 'sub-094A',\n",
       " 'sub-095A',\n",
       " 'sub-095B',\n",
       " 'sub-096A',\n",
       " 'sub-096B',\n",
       " 'sub-097A',\n",
       " 'sub-097B',\n",
       " 'sub-098A',\n",
       " 'sub-098B',\n",
       " 'sub-099A',\n",
       " 'sub-099B',\n",
       " 'sub-100A',\n",
       " 'sub-100B',\n",
       " 'sub-101A',\n",
       " 'sub-101B',\n",
       " 'sub-102A',\n",
       " 'sub-102B',\n",
       " 'sub-103A',\n",
       " 'sub-103B',\n",
       " 'sub-104A',\n",
       " 'sub-104B',\n",
       " 'sub-105A',\n",
       " 'sub-105B',\n",
       " 'sub-106A',\n",
       " 'sub-106B',\n",
       " 'sub-107A',\n",
       " 'sub-107B',\n",
       " 'sub-108A',\n",
       " 'sub-108B',\n",
       " 'sub-109A',\n",
       " 'sub-109B',\n",
       " 'sub-110A',\n",
       " 'sub-110B',\n",
       " 'sub-111A',\n",
       " 'sub-111B',\n",
       " 'sub-112A',\n",
       " 'sub-112B',\n",
       " 'sub-113A',\n",
       " 'sub-114A',\n",
       " 'sub-114B',\n",
       " 'sub-115A',\n",
       " 'sub-115B',\n",
       " 'sub-116A',\n",
       " 'sub-116B',\n",
       " 'sub-117A',\n",
       " 'sub-117B',\n",
       " 'sub-118A',\n",
       " 'sub-118B',\n",
       " 'sub-119A',\n",
       " 'sub-119B',\n",
       " 'sub-120A',\n",
       " 'sub-120B',\n",
       " 'sub-121A',\n",
       " 'sub-121B',\n",
       " 'sub-122A',\n",
       " 'sub-122B',\n",
       " 'sub-123A',\n",
       " 'sub-123B',\n",
       " 'sub-124A',\n",
       " 'sub-124B',\n",
       " 'sub-125A',\n",
       " 'sub-125B',\n",
       " 'sub-126A',\n",
       " 'sub-126B',\n",
       " 'sub-127A',\n",
       " 'sub-127B',\n",
       " 'sub-128A',\n",
       " 'sub-128B',\n",
       " 'sub-129A',\n",
       " 'sub-129B',\n",
       " 'sub-130A',\n",
       " 'sub-130B',\n",
       " 'sub-131A',\n",
       " 'sub-131B',\n",
       " 'sub-132A',\n",
       " 'sub-132B',\n",
       " 'sub-133A',\n",
       " 'sub-133B',\n",
       " 'sub-134A',\n",
       " 'sub-134B',\n",
       " 'sub-135A',\n",
       " 'sub-135B',\n",
       " 'sub-136A',\n",
       " 'sub-136B',\n",
       " 'sub-137A',\n",
       " 'sub-137B',\n",
       " 'sub-137C',\n",
       " 'sub-138A',\n",
       " 'sub-138B',\n",
       " 'sub-139A',\n",
       " 'sub-139B',\n",
       " 'sub-140A',\n",
       " 'sub-140B',\n",
       " 'sub-141A',\n",
       " 'sub-141B',\n",
       " 'sub-142A',\n",
       " 'sub-142B',\n",
       " 'sub-143A',\n",
       " 'sub-144A',\n",
       " 'sub-144B',\n",
       " 'sub-145A',\n",
       " 'sub-145B',\n",
       " 'sub-146A',\n",
       " 'sub-146B',\n",
       " 'sub-147A',\n",
       " 'sub-147B',\n",
       " 'sub-148A',\n",
       " 'sub-148B',\n",
       " 'sub-149A',\n",
       " 'sub-149B',\n",
       " 'sub-150A',\n",
       " 'sub-150B',\n",
       " 'sub-151A',\n",
       " 'sub-151B',\n",
       " 'sub-152A',\n",
       " 'sub-152B',\n",
       " 'sub-152C',\n",
       " 'sub-153A',\n",
       " 'sub-153B',\n",
       " 'sub-154A',\n",
       " 'sub-154B',\n",
       " 'sub-155A',\n",
       " 'sub-155B',\n",
       " 'sub-156A',\n",
       " 'sub-156B',\n",
       " 'sub-157A',\n",
       " 'sub-157B',\n",
       " 'sub-158A',\n",
       " 'sub-158B',\n",
       " 'sub-159A',\n",
       " 'sub-159B',\n",
       " 'sub-160A',\n",
       " 'sub-160B',\n",
       " 'sub-161A',\n",
       " 'sub-161B',\n",
       " 'sub-162A',\n",
       " 'sub-162B',\n",
       " 'sub-163A',\n",
       " 'sub-163B',\n",
       " 'sub-164A',\n",
       " 'sub-164B',\n",
       " 'sub-165A',\n",
       " 'sub-165B',\n",
       " 'sub-166A',\n",
       " 'sub-166B',\n",
       " 'sub-167A',\n",
       " 'sub-168A',\n",
       " 'sub-168B',\n",
       " 'sub-169A',\n",
       " 'sub-169B',\n",
       " 'sub-170A',\n",
       " 'sub-170B',\n",
       " 'sub-171A',\n",
       " 'sub-171B',\n",
       " 'sub-172A',\n",
       " 'sub-173A',\n",
       " 'sub-173B',\n",
       " 'sub-174A',\n",
       " 'sub-174B',\n",
       " 'sub-175A',\n",
       " 'sub-175B',\n",
       " 'sub-176A',\n",
       " 'sub-176B',\n",
       " 'sub-177A',\n",
       " 'sub-177B',\n",
       " 'sub-178A',\n",
       " 'sub-178B',\n",
       " 'sub-179A',\n",
       " 'sub-179B',\n",
       " 'sub-180A',\n",
       " 'sub-180B',\n",
       " 'sub-180C',\n",
       " 'sub-181A',\n",
       " 'sub-181B',\n",
       " 'sub-182A',\n",
       " 'sub-182B',\n",
       " 'sub-183A',\n",
       " 'sub-183B',\n",
       " 'sub-184A',\n",
       " 'sub-184B',\n",
       " 'sub-185A',\n",
       " 'sub-185B',\n",
       " 'sub-186A',\n",
       " 'sub-186B',\n",
       " 'sub-187A',\n",
       " 'sub-187B',\n",
       " 'sub-188A',\n",
       " 'sub-188B',\n",
       " 'sub-189A',\n",
       " 'sub-189B',\n",
       " 'sub-190A',\n",
       " 'sub-190B',\n",
       " 'sub-191A',\n",
       " 'sub-191B',\n",
       " 'sub-192A',\n",
       " 'sub-192B',\n",
       " 'sub-193A',\n",
       " 'sub-193B',\n",
       " 'sub-194A',\n",
       " 'sub-194B',\n",
       " 'sub-195A',\n",
       " 'sub-195B',\n",
       " 'sub-196A',\n",
       " 'sub-196B',\n",
       " 'sub-197A',\n",
       " 'sub-197B',\n",
       " 'sub-198A',\n",
       " 'sub-198B',\n",
       " 'sub-199A',\n",
       " 'sub-199B',\n",
       " 'sub-200A',\n",
       " 'sub-200B',\n",
       " 'sub-201A',\n",
       " 'sub-201B',\n",
       " 'sub-202A',\n",
       " 'sub-202B',\n",
       " 'sub-203A',\n",
       " 'sub-203B',\n",
       " 'sub-204A',\n",
       " 'sub-204B',\n",
       " 'sub-205A',\n",
       " 'sub-205B',\n",
       " 'sub-206A',\n",
       " 'sub-206B',\n",
       " 'sub-207A',\n",
       " 'sub-208A',\n",
       " 'sub-208B',\n",
       " 'sub-209A',\n",
       " 'sub-209B',\n",
       " 'sub-210A',\n",
       " 'sub-210B',\n",
       " 'sub-211A',\n",
       " 'sub-211B',\n",
       " 'sub-212A',\n",
       " 'sub-212B',\n",
       " 'sub-213A',\n",
       " 'sub-213B',\n",
       " 'sub-214A',\n",
       " 'sub-215A',\n",
       " 'sub-216A',\n",
       " 'sub-216B',\n",
       " 'sub-217A',\n",
       " 'sub-217B',\n",
       " 'sub-218A',\n",
       " 'sub-218B',\n",
       " 'sub-219A',\n",
       " 'sub-220A',\n",
       " 'sub-220B',\n",
       " 'sub-221A',\n",
       " 'sub-221B',\n",
       " 'sub-222A',\n",
       " 'sub-222B',\n",
       " 'sub-223A',\n",
       " 'sub-223B',\n",
       " 'sub-224A',\n",
       " 'sub-224B',\n",
       " 'sub-225A',\n",
       " 'sub-225B',\n",
       " 'sub-226A',\n",
       " 'sub-226B',\n",
       " 'sub-227A',\n",
       " 'sub-227B',\n",
       " 'sub-228A',\n",
       " 'sub-228B']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_dataset_path = Path('/misc/geminis2/ramirezd/test_bet/')\n",
    "glob_characters = '[a-z,A-Z,0-9,\\\\,\\/,\\-,_,\\.,\\*,\\[,\\],\\:,\\+,\\?,\\!]'\n",
    "regex_characters = '[a-z,A-Z,0-9,\\\\\\,\\/,\\-,_,\\.,\\*,\\[,\\],\\:,\\+,\\?,\\!,\\(,\\),\\<,\\>]'\n",
    "\n",
    "\n",
    "if '<!glob>' in pattern and not '<!in>':\n",
    "    try:\n",
    "        globbing = re.search(f\"(?<=\\<!glob\\>\\(){glob_characters}+(?=\\))\", pattern).group()\n",
    "        vals = sorted([str(path) for path in Path(super_dataset_path).glob(globbing)])\n",
    "    except:\n",
    "        raise Exception('Not a valid globbing pattern.')\n",
    "if '<!regex>' in pattern:\n",
    "    regex = re.search(f\"(?<=\\<!regex\\>\\(){regex_characters}+(?=\\)$)\", pattern.replace('<!unique>','').strip()).group()\n",
    "    vals = [try_search(regex, val) for val in vals]\n",
    "    if all(val is None for val in vals):\n",
    "        raise Exception(\"Not a valid regex or no matches.\")\n",
    "if '<!unique>' in pattern:\n",
    "    vals = sorted(set(vals))\n",
    "    \n",
    "\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub-\\\\w+'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject = sub-001A sub-001B '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_vals.split(';')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acc pcc * subject'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict = {}\n",
    "for key_val in key_vals.split(';'):\n",
    "    key_val = key_val.split('==')\n",
    "    key = key_val[0].strip()\n",
    "    pattern = key_val[1].strip()\n",
    "    \n",
    "    if '*' in pattern:\n",
    "        vals = vals_plus.split('*')[0].split()\n",
    "        len_key = vals_plus.split('*')[1].strip()\n",
    "        \n",
    "        if is_numeric(len_key):\n",
    "            n_elements = int(len_key)\n",
    "        else:\n",
    "            n_elements = len(variable_dict[len_key])\n",
    "            \n",
    "        vals = [[val]*n_elements for val in vals]\n",
    "        vals = functools.reduce(operator.iconcat, vals, [])\n",
    "    else:\n",
    "        vals = vals_plus.split()\n",
    "        \n",
    "    variable_dict[key] = vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': ['sub-001A', 'sub-001B'], 'voi': ['acc', 'acc', 'pcc', 'pcc']}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_dataset = 'fair_test'\n",
    "input_datasets = ['/misc/geminis2/twinsmx/datasets/mri_study/mri_study-raw/mri-raw/']\n",
    "output_datasets = ['bet']\n",
    "container_dataset = '/misc/geminis2/containers/'\n",
    "container_name = 'fsl-6-0-4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Running procedure cfg_yoda \n",
      "[INFO] == Command start (output follows) ===== \n",
      "[INFO] == Command exit (modification check follows) ===== \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run(ok): /misc/geminis2/ramirezd/fb_test/fair_test (dataset) [/misc/geminis/ramirezd/miniconda3/envs/p...]\n",
      "create(ok): /misc/geminis2/ramirezd/fb_test/fair_test (dataset)\n",
      "action summary:\n",
      "  create (ok: 1)\n",
      "  run (ok: 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset('/misc/geminis2/ramirezd/fb_test/fair_test')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.create(super_dataset, cfg_proc='yoda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_root = Path(super_dataset) / 'inputs'\n",
    "inputs_root.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Attempting a clone into /misc/geminis2/ramirezd/fb_test/fair_test/inputs/mri-raw \n",
      "[INFO] Attempting to clone from /misc/geminis2/twinsmx/datasets/mri_study/mri_study-raw/mri-raw/ to /misc/geminis2/ramirezd/fb_test/fair_test/inputs/mri-raw \n",
      "[INFO] Completed clone attempts for Dataset(/misc/geminis2/ramirezd/fb_test/fair_test/inputs/mri-raw) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "install(ok): inputs/mri-raw (dataset)\n",
      "add(ok): inputs/mri-raw (dataset)\n",
      "add(ok): .gitmodules (file)\n",
      "save(ok): . (dataset)\n",
      "add(ok): .gitmodules (file)\n",
      "save(ok): . (dataset)\n",
      "action summary:\n",
      "  add (ok: 3)\n",
      "  install (ok: 1)\n",
      "  save (ok: 2)\n"
     ]
    }
   ],
   "source": [
    "for input_dataset in input_datasets:\n",
    "    input_dataset_path = str(inputs_root / Path(input_dataset).stem)\n",
    "    dl.clone(input_dataset, input_dataset_path, dataset=super_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fair_test/inputs/containers/.datalad/environments/fsl-6-0-4/image'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Attempting a clone into /misc/geminis2/ramirezd/fb_test/fair_test/inputs/containers \n",
      "[INFO] Attempting to clone from /misc/geminis2/containers/ to /misc/geminis2/ramirezd/fb_test/fair_test/inputs/containers \n",
      "[INFO] Completed clone attempts for Dataset(/misc/geminis2/ramirezd/fb_test/fair_test/inputs/containers) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "install(ok): inputs/containers (dataset)\n",
      "add(ok): inputs/containers (dataset)\n",
      "add(ok): .gitmodules (file)\n",
      "save(ok): . (dataset)\n",
      "add(ok): .gitmodules (file)\n",
      "save(ok): . (dataset)\n",
      "action summary:\n",
      "  add (ok: 3)\n",
      "  install (ok: 1)\n",
      "  save (ok: 2)\n",
      "add(ok): .datalad/config (file)\n",
      "save(ok): . (dataset)\n",
      "action summary:\n",
      "  add (ok: 1)\n",
      "  save (ok: 1)\n",
      "add(ok): .datalad/config (file)\n",
      "save(ok): . (dataset)\n",
      "containers_add(ok): /misc/geminis2/ramirezd/fb_test/fair_test/inputs/containers/.datalad/environments/fsl-6-0-4/image (file)\n",
      "action summary:\n",
      "  add (ok: 1)\n",
      "  containers_add (ok: 1)\n",
      "  save (ok: 1)\n"
     ]
    }
   ],
   "source": [
    "if container_dataset and container_name:\n",
    "    input_container_dataset_path = str(inputs_root / 'containers')\n",
    "    image_path = str(Path(input_container_dataset_path) / '.datalad' / 'environments' / container_name / 'image')\n",
    "    dl.clone(container_dataset, input_container_dataset_path, dataset=super_dataset)\n",
    "    dl.containers_add(container_name, call_fmt=\"apptainer run -e {img} {cmd}\", image=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add(ok): outputs/bet (dataset)\n",
      "add(ok): .gitmodules (file)\n",
      "save(ok): . (dataset)\n",
      "create(ok): outputs/bet (dataset)\n",
      "action summary:\n",
      "  add (ok: 2)\n",
      "  create (ok: 1)\n",
      "  save (ok: 1)\n"
     ]
    }
   ],
   "source": [
    "outputs_root = Path(super_dataset) / 'outputs'\n",
    "outputs_root.mkdir()\n",
    "for output_dataset in output_datasets:\n",
    "    output_dataset_path = str(outputs_root / output_dataset)\n",
    "    dl.create(output_dataset_path, dataset=super_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add(ok): .gitignore (file)\n",
      "save(ok): . (dataset)\n",
      "action summary:\n",
      "  add (ok: 1)\n",
      "  save (ok: 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'action': 'add',\n",
       "  'path': '/misc/geminis2/ramirezd/fb_test/fair_test/.gitignore',\n",
       "  'type': 'file',\n",
       "  'refds': '/misc/geminis2/ramirezd/fb_test/fair_test',\n",
       "  'status': 'ok',\n",
       "  'message': '',\n",
       "  'key': None},\n",
       " {'action': 'save',\n",
       "  'type': 'dataset',\n",
       "  'path': '/misc/geminis2/ramirezd/fb_test/fair_test',\n",
       "  'refds': '/misc/geminis2/ramirezd/fb_test/fair_test',\n",
       "  'status': 'ok'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gitignore_path = Path(super_dataset) / '.gitignore'\n",
    "with open(gitignore_path, 'w') as gitignore_file:\n",
    "    gitignore_file.write('.fairlybig')\n",
    "dl.save(dataset=super_dataset, message='Add .gitignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_dataset_id = dl.Dataset(super_dataset).id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/misc/geminis2/ramirezd/fb_test/fair_test/.fairlybig/input_ria'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ria_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Creating a new RIA store at /misc/geminis2/ramirezd/fb_test/fair_test/.fairlybig/output_ria \n",
      "[INFO] create siblings 'output_ria' and 'output_ria-storage' ... \n",
      "[INFO] Fetching updates for Dataset(/misc/geminis2/ramirezd/fb_test/fair_test) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update(ok): . (dataset)\n",
      "update(ok): . (dataset)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Configure additional publication dependency on \"output_ria-storage\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configure-sibling(ok): . (sibling)\n",
      "create-sibling-ria(ok): /misc/geminis2/ramirezd/fb_test/fair_test (dataset)\n",
      "action summary:\n",
      "  configure-sibling (ok: 1)\n",
      "  create-sibling-ria (ok: 1)\n",
      "  update (ok: 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Creating a new RIA store at /misc/geminis2/ramirezd/fb_test/fair_test/.fairlybig/input_ria \n",
      "[INFO] create siblings 'input_ria' and 'input_ria-storage' ... \n",
      "[INFO] Fetching updates for Dataset(/misc/geminis2/ramirezd/fb_test/fair_test) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update(ok): . (dataset)\n",
      "update(ok): . (dataset)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Configure additional publication dependency on \"input_ria-storage\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configure-sibling(ok): . (sibling)\n",
      "create-sibling-ria(ok): /misc/geminis2/ramirezd/fb_test/fair_test (dataset)\n",
      "action summary:\n",
      "  configure-sibling (ok: 1)\n",
      "  create-sibling-ria (ok: 1)\n",
      "  update (ok: 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'action': 'update',\n",
       "  'path': '/misc/geminis2/ramirezd/fb_test/fair_test',\n",
       "  'type': 'dataset',\n",
       "  'refds': '/misc/geminis2/ramirezd/fb_test/fair_test',\n",
       "  'status': 'ok'},\n",
       " {'action': 'configure-sibling',\n",
       "  'path': '/misc/geminis2/ramirezd/fb_test/fair_test',\n",
       "  'type': 'sibling',\n",
       "  'name': 'input_ria',\n",
       "  'annex-ignore': True,\n",
       "  'url': '/misc/geminis2/ramirezd/fb_test/fair_test/.fairlybig/input_ria/94f/905fe-dccb-4d0f-8fde-230d5f0e2520',\n",
       "  'fetch': '+refs/heads/*:refs/remotes/input_ria/*',\n",
       "  'datalad-publish-depends': 'input_ria-storage',\n",
       "  'status': 'ok',\n",
       "  'refds': '/misc/geminis2/ramirezd/fb_test/fair_test'},\n",
       " {'action': 'create-sibling-ria',\n",
       "  'path': '/misc/geminis2/ramirezd/fb_test/fair_test',\n",
       "  'type': 'dataset',\n",
       "  'status': 'ok'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ria_path = str((Path(super_dataset) / '.fairlybig' / 'output_ria').absolute())\n",
    "input_ria_path = str((Path(super_dataset) / '.fairlybig' / 'input_ria').absolute())\n",
    "\n",
    "dl.create_sibling_ria(\n",
    "    f'ria+file://{output_ria_path}',\n",
    "    name='output_ria',\n",
    "    dataset=super_dataset,\n",
    "    new_store_ok=True,\n",
    ")\n",
    "\n",
    "dl.create_sibling_ria(\n",
    "    f'ria+file://{input_ria_path}',\n",
    "    name='input_ria',\n",
    "    dataset=super_dataset,\n",
    "    new_store_ok=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Determine push target \n",
      "[INFO] Push refspecs \n",
      "[INFO] Determine push target \n",
      "[INFO] Push refspecs \n",
      "[INFO] Transfer data \n",
      "[INFO] Transfer data \n",
      "[INFO] Update availability information \n",
      "[INFO] Start enumerating objects \n",
      "[INFO] Start counting objects \n",
      "[INFO] Start compressing objects \n",
      "[INFO] Start writing objects \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish(ok): . (dataset) [refs/heads/master->output_ria:refs/heads/master [new branch]]\n",
      "publish(ok): . (dataset) [refs/heads/git-annex->output_ria:refs/heads/git-annex [new branch]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Finished push of Dataset(/misc/geminis2/ramirezd/fb_test/fair_test) \n",
      "[INFO] Finished push of Dataset(/misc/geminis2/ramirezd/fb_test/fair_test) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action summary:\n",
      "  publish (ok: 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Determine push target \n",
      "[INFO] Push refspecs \n",
      "[INFO] Determine push target \n",
      "[INFO] Push refspecs \n",
      "[INFO] Transfer data \n",
      "[INFO] Transfer data \n",
      "[INFO] Update availability information \n",
      "[INFO] Start enumerating objects \n",
      "[INFO] Start counting objects \n",
      "[INFO] Start compressing objects \n",
      "[INFO] Start writing objects \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish(ok): . (dataset) [refs/heads/master->input_ria:refs/heads/master [new branch]]\n",
      "publish(ok): . (dataset) [refs/heads/git-annex->input_ria:refs/heads/git-annex [new branch]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Finished push of Dataset(/misc/geminis2/ramirezd/fb_test/fair_test) \n",
      "[INFO] Finished push of Dataset(/misc/geminis2/ramirezd/fb_test/fair_test) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action summary:\n",
      "  publish (ok: 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'action': 'publish',\n",
       "  'refds': '/misc/geminis2/ramirezd/fb_test/fair_test',\n",
       "  'type': 'dataset',\n",
       "  'path': '/misc/geminis2/ramirezd/fb_test/fair_test',\n",
       "  'status': 'ok',\n",
       "  'target': 'input_ria',\n",
       "  'refspec': 'refs/heads/master:refs/heads/master',\n",
       "  'operations': ['new-branch'],\n",
       "  'hints': None,\n",
       "  'message': 'refs/heads/master->input_ria:refs/heads/master [new branch]'},\n",
       " {'action': 'publish',\n",
       "  'refds': '/misc/geminis2/ramirezd/fb_test/fair_test',\n",
       "  'type': 'dataset',\n",
       "  'path': '/misc/geminis2/ramirezd/fb_test/fair_test',\n",
       "  'status': 'ok',\n",
       "  'target': 'input_ria',\n",
       "  'refspec': 'refs/heads/git-annex:refs/heads/git-annex',\n",
       "  'operations': ['new-branch'],\n",
       "  'hints': None,\n",
       "  'message': 'refs/heads/git-annex->input_ria:refs/heads/git-annex [new branch]'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.push(dataset=super_dataset, to='output_ria')\n",
    "dl.push(dataset=super_dataset, to='input_ria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Creating a new RIA store at /misc/geminis2/ramirezd/fb_test/fair_test/.fairlybig/output_ria \n",
      "[INFO] create siblings 'output_ria' and 'output_ria-storage' ... \n",
      "[INFO] Fetching updates for Dataset(/misc/geminis2/ramirezd/fb_test/fair_test/outputs/bet) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update(ok): . (dataset)\n",
      "update(ok): . (dataset)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Configure additional publication dependency on \"output_ria-storage\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configure-sibling(ok): . (sibling)\n",
      "create-sibling-ria(ok): /misc/geminis2/ramirezd/fb_test/fair_test/outputs/bet (dataset)\n",
      "action summary:\n",
      "  configure-sibling (ok: 1)\n",
      "  create-sibling-ria (ok: 1)\n",
      "  update (ok: 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Creating a new RIA store at /misc/geminis2/ramirezd/fb_test/fair_test/.fairlybig/input_ria \n",
      "[INFO] create siblings 'input_ria' and 'input_ria-storage' ... \n",
      "[INFO] Fetching updates for Dataset(/misc/geminis2/ramirezd/fb_test/fair_test/outputs/bet) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update(ok): . (dataset)\n",
      "update(ok): . (dataset)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Configure additional publication dependency on \"input_ria-storage\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configure-sibling(ok): . (sibling)\n",
      "create-sibling-ria(ok): /misc/geminis2/ramirezd/fb_test/fair_test/outputs/bet (dataset)\n",
      "action summary:\n",
      "  configure-sibling (ok: 1)\n",
      "  create-sibling-ria (ok: 1)\n",
      "  update (ok: 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Determine push target \n",
      "[INFO] Push refspecs \n",
      "[INFO] Determine push target \n",
      "[INFO] Push refspecs \n",
      "[INFO] Transfer data \n",
      "[INFO] Transfer data \n",
      "[INFO] Update availability information \n",
      "[INFO] Start enumerating objects \n",
      "[INFO] Start counting objects \n",
      "[INFO] Start compressing objects \n",
      "[INFO] Start writing objects \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish(ok): . (dataset) [refs/heads/master->output_ria:refs/heads/master [new branch]]\n",
      "publish(ok): . (dataset) [refs/heads/git-annex->output_ria:refs/heads/git-annex [new branch]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Finished push of Dataset(/misc/geminis2/ramirezd/fb_test/fair_test/outputs/bet) \n",
      "[INFO] Finished push of Dataset(/misc/geminis2/ramirezd/fb_test/fair_test/outputs/bet) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action summary:\n",
      "  publish (ok: 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Determine push target \n",
      "[INFO] Push refspecs \n",
      "[INFO] Determine push target \n",
      "[INFO] Push refspecs \n",
      "[INFO] Transfer data \n",
      "[INFO] Transfer data \n",
      "[INFO] Update availability information \n",
      "[INFO] Start enumerating objects \n",
      "[INFO] Start counting objects \n",
      "[INFO] Start compressing objects \n",
      "[INFO] Start writing objects \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish(ok): . (dataset) [refs/heads/master->input_ria:refs/heads/master [new branch]]\n",
      "publish(ok): . (dataset) [refs/heads/git-annex->input_ria:refs/heads/git-annex [new branch]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Finished push of Dataset(/misc/geminis2/ramirezd/fb_test/fair_test/outputs/bet) \n",
      "[INFO] Finished push of Dataset(/misc/geminis2/ramirezd/fb_test/fair_test/outputs/bet) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action summary:\n",
      "  publish (ok: 2)\n"
     ]
    }
   ],
   "source": [
    "for output_dataset in output_datasets:\n",
    "    \n",
    "    output_dataset_path = str(outputs_root / output_dataset)\n",
    "    \n",
    "    dl.create_sibling_ria(\n",
    "        f'ria+file://{output_ria_path}',\n",
    "        name='output_ria',\n",
    "        dataset=output_dataset_path\n",
    "    )\n",
    "\n",
    "    dl.create_sibling_ria(\n",
    "        f'ria+file://{input_ria_path}',\n",
    "        name='input_ria',\n",
    "        dataset=output_dataset_path\n",
    "    )\n",
    "    \n",
    "    dl.push(dataset=output_dataset_path, to='output_ria')\n",
    "    dl.push(dataset=output_dataset_path, to='input_ria')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_datasets:\n",
    "    output_datasets_string = ''\n",
    "    for output_dataset in output_datasets:\n",
    "        output_datasets_string += f'{output_dataset} '\n",
    "    output_datasets_string = output_datasets_string.strip()\n",
    "else:\n",
    "    output_datasets_string = None\n",
    "\n",
    "user = os.getenv('USER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config_dict ={\n",
    "    'job_name':[None],\n",
    "    'dl_cmd':[None],\n",
    "    'container':[container_name],\n",
    "    'commit':[None],\n",
    "    'inputs':[None],\n",
    "    'outputs':[None],\n",
    "    'is_explicit':[False],\n",
    "    'output_datasets':[output_datasets_string],\n",
    "    'prereq_get':[None],\n",
    "    'message':[None],\n",
    "    'super_id':[super_dataset_id],\n",
    "    'clone_target':[input_ria_path],\n",
    "    'push_target':[output_ria_path],\n",
    "    'ephemeral_location':[\"/tmp /misc/{host}[0-9]/\"+user],\n",
    "    'req_disk_gb':[None],\n",
    "    'queue':['all.q'],\n",
    "    'slots':[None],\n",
    "    'vmem':[None],\n",
    "    'h_rt':[None],\n",
    "    'env_vars':[None],\n",
    "    'batch':['0001']\n",
    "}\n",
    "\n",
    "fairlybig_path = Path(super_dataset) / '.fairlybig'\n",
    "(fairlybig_path / 'code').mkdir()\n",
    "\n",
    "pd.DataFrame(job_config_dict).to_csv(str(fairlybig_path / 'code' / 'job_config.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-minis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 08:57:19) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b7ca23d180daa64c5df23970c68613774f6face07a17b610016dc57dc2566e45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
