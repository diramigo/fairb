{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import re\n",
    "from filelock import FileLock\n",
    "from datetime import datetime\n",
    "\n",
    "import datalad.api as dl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = 'test'\n",
    "job_id = '1111'\n",
    "status_csv = '/misc/geminis2/ramirezd/fb_test/code/status.csv'\n",
    "status_lockfile = '/misc/geminis2/ramirezd/fb_test/code/status_job.lock'\n",
    "super_ds_id = 'f5db201b-6eed-46ee-8c97-b586f3f694e6'\n",
    "clone_target = '/misc/geminis2/ramirezd/test_bet/.fairlybig/input_ria/'\n",
    "push_target = '/misc/geminis2/ramirezd/test_bet/.fairlybig/output_ria/'\n",
    "push_lockfile = '/misc/geminis2/ramirezd/fb_test/code/status_job.lock'\n",
    "inputs = 'inputs/mri-raw/sub-001A/anat/sub-001A_T1w.nii.gz'\n",
    "outputs = 'outputs/sub-001A_T1w_bet.nii.gz'\n",
    "output_datasets = None\n",
    "preget_inputs = None\n",
    "is_explicit = False\n",
    "dl_cmd = 'bet inputs/mri-raw/sub-001A/anat/sub-001A_T1w.nii.gz outputs/sub-001A_T1w_bet.nii.gz'\n",
    "commit = None\n",
    "container = 'fsl-6-0-4'\n",
    "message = None\n",
    "ephemeral_locations = ['/tmp', '/misc/{host}[0-9]/ramirezd']\n",
    "req_disk_gb = 40\n",
    "\n",
    "host = os.uname().nodename\n",
    "user= os.getenv('USER')\n",
    "\n",
    "status_lock = FileLock(status_lockfile)\n",
    "push_lock = FileLock(push_lockfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for disk space management\n",
    "def get_locations(location_list):\n",
    "    \"\"\"\n",
    "    Return tmp and non_tmp locations from the list of location patterns.\n",
    "    \"\"\"\n",
    "    \n",
    "    tmp=[]\n",
    "    not_tmp_patterns=[]\n",
    "    not_tmp_locations=[]\n",
    "\n",
    "    # tmp and non_tmp list\n",
    "    for location in location_list:\n",
    "        if location == '/tmp' or location == '/tmp/':\n",
    "            tmp.append(location)\n",
    "        else:\n",
    "            not_tmp_patterns.append(location)\n",
    "    \n",
    "    # get non_tmp locations according to the non_tmp_patterns (the script can accept multiple location patterns)\n",
    "    for not_tmp_pattern in not_tmp_patterns:\n",
    "        \n",
    "        for index, part in enumerate(Path(not_tmp_pattern).parts):\n",
    "            if host in part:\n",
    "                break\n",
    "\n",
    "        # node location\n",
    "        mount_pattern = str(Path(*list(Path(not_tmp_pattern).parts[:index+1])))\n",
    "        # location inside node\n",
    "        after_pattern = str(Path(*list(Path(not_tmp_pattern).parts[index+1:])))\n",
    "        \n",
    "        # make sure those locations are within the node with the /etc/mtab file\n",
    "        with open('/etc/mtab', 'r') as mtab:\n",
    "            for line in mtab.readlines():\n",
    "                # which mount pattern is within the node\n",
    "                pattern = re.search(f'{mount_pattern} ', line)\n",
    "                # which directories (after mount pattern) are within that mount\n",
    "                if pattern:\n",
    "                    pattern_glob = Path(pattern.group().strip()).glob(after_pattern) \n",
    "                else:\n",
    "                    continue\n",
    "                # after mount pattern could retrieve multiple locations\n",
    "                if pattern_glob: \n",
    "                    not_tmp_locations += [str(pg) for pg in pattern_glob]\n",
    "    \n",
    "    return tmp, not_tmp_locations\n",
    "\n",
    "\n",
    "def get_free_disk(location):\n",
    "    \"\"\"\n",
    "    Return location's free disk space in gb.\n",
    "    \"\"\"\n",
    "    \n",
    "    _total, _used, free = shutil.disk_usage(location)\n",
    "    # transform to gb\n",
    "    return free // (2**30)\n",
    "\n",
    "\n",
    "def get_used_disk(location):\n",
    "    \"\"\"\n",
    "    Return location's used disk space in gb.\n",
    "    \"\"\"\n",
    "    \n",
    "    _total, used, _free = shutil.disk_usage(location)\n",
    "    # transform to gb\n",
    "    return used // (2**30)\n",
    "\n",
    "\n",
    "def get_available_disk_resource(location, host, status_csv):\n",
    "    \"\"\"\n",
    "    Return available disk space (in gb) resource.\n",
    "    \"\"\"\n",
    "    \n",
    "    total_req_disk_others_gb = (pd.read_csv(status_csv)\n",
    "    .query(\"location == @location and status == 'ongoing' and host == @host\")\n",
    "    .assign(\n",
    "        used_disk_gb = lambda df_: \n",
    "            df_['location'].apply(lambda x_: get_used_disk(x_)),\n",
    "        req_disk_gb = lambda df_: \n",
    "            (df_['req_disk_gb'] - df_['used_disk_gb'])\n",
    "    )\n",
    "    .assign(\n",
    "        req_disk_gb = lambda df_: \n",
    "            df_['req_disk_gb'].mask(df_['req_disk_gb'] < 0, 0)\n",
    "    )\n",
    "    ['req_disk_gb']\n",
    "    .sum()\n",
    "    )\n",
    "        \n",
    "    current_free_gb = get_free_disk(location)\n",
    "    \n",
    "    return current_free_gb - total_req_disk_others_gb\n",
    "\n",
    "\n",
    "def set_status(status_csv, job_name, job_id, req_disk_gb, host, location, job_dir, status, start):\n",
    "    \"\"\"\n",
    "    Add a new job status.\n",
    "    \"\"\"\n",
    "    \n",
    "    status_df = pd.read_csv(status_csv)\n",
    "    \n",
    "    new_status = {\n",
    "        'job_name':[job_name],\n",
    "        'job_id':[job_id],\n",
    "        'req_disk_gb':[req_disk_gb],\n",
    "        'host':[host],\n",
    "        'location':[location],\n",
    "        'job_dir':[job_dir],\n",
    "        'status':[status],\n",
    "        'start':[start],\n",
    "        'update':[None],\n",
    "        'traceback':[None]\n",
    "        }\n",
    "    \n",
    "    new_status = pd.DataFrame(new_status)\n",
    "    \n",
    "    status_df = pd.concat([status_df, new_status])\n",
    "    \n",
    "    status_df.to_csv(status_csv, index=False)\n",
    "    \n",
    "    return status_df\n",
    "\n",
    "\n",
    "def update_status(status_csv, job_name, id, host, location, status, update, traceback=None):\n",
    "    \"\"\"\n",
    "    Update an existing job status.\n",
    "    \"\"\"\n",
    "    \n",
    "    status_df = pd.read_csv(status_csv)\n",
    "    \n",
    "    is_job = (\n",
    "    (status_df['job_name'] == job_name) and\n",
    "    (status_df['id'] == id) and\n",
    "    (status_df['host'] == host) and\n",
    "    (status_df['location'] == location) \n",
    "    )\n",
    "    \n",
    "    status_df = (status_df\n",
    "    .assign(\n",
    "        status = lambda df_: df_['status'].mask(is_job, status),\n",
    "        update = update,\n",
    "        traceback = lambda df_: df_['traceback'].mask(is_job, traceback)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    status_df.to_csv(status_csv, index=False)\n",
    "    \n",
    "    return status_df\n",
    "\n",
    "\n",
    "# Functions for cloning and checking out\n",
    "def do_dead_annex(dpath='cwd'):\n",
    "    \"\"\"\n",
    "    Set cwd as dead annex or submodules as dead annex.\n",
    "    \"\"\"\n",
    "    if dpath == 'cwd':\n",
    "        cmd = ['git', 'annex', 'dead', 'here']\n",
    "    else: \n",
    "        cmd = ['git', 'submodule', 'foreach', '--recursive', 'git', 'annex', 'dead', 'here']\n",
    "    subprocess.run(cmd)\n",
    "    \n",
    "\n",
    "def do_checkout(job_name, dpath='cwd'):\n",
    "    \"\"\"\n",
    "    Change to a job branch.\n",
    "    \"\"\"\n",
    "    if dpath == 'cwd':\n",
    "        cmd = ['git', 'checkout', '-b', job_name]\n",
    "    else:\n",
    "        cmd = ['git', '-C', dpath ,'checkout', '-b', job_name]\n",
    "    \n",
    "    subprocess.run(cmd)\n",
    "    \n",
    "def get_private_subdataset(clone_target, sd_path, sd_id):\n",
    "    # Assume clone_target is a RIA store\n",
    "    clone_path = str(Path(clone_target) / Path(sd_id[:3]) / Path(sd_id[3:]))\n",
    "    \n",
    "    ampersand = ['&&']\n",
    "    git_clone_command = ['git', 'clone', clone_path, sd_path]\n",
    "    git_config_annex_private = ['git', '-C', sd_path, 'config', 'annex.private', 'true']\n",
    "    git_annex_init = ['git', '-C', sd_path, 'annex', 'init']\n",
    "    \n",
    "    cmd = git_clone_command + ampersand + git_config_annex_private + ampersand + git_annex_init\n",
    "    \n",
    "    subprocess.run(cmd, shell=True)\n",
    "\n",
    "def git_add_remote(push_path, dpath='cwd'):\n",
    "    if dpath == 'cwd':\n",
    "        cmd = ['git', 'remote', 'add', 'outputstore', push_path]\n",
    "    else:\n",
    "        cmd = ['git', '-C', dpath, 'remote', 'add', 'outputstore', push_path]\n",
    "        \n",
    "    subprocess.run(cmd)\n",
    "\n",
    "def git_push(dpath='cwd'):\n",
    "    if dpath == 'cwd':\n",
    "        cmd = ['git', 'push', 'outputstore']\n",
    "    else:\n",
    "        cmd = ['git', '-C', dpath, 'push', 'outputstore']\n",
    "    \n",
    "    subprocess.run(cmd)\n",
    "\n",
    "\n",
    "# cleanup and exception handling\n",
    "def cleanup(job_dir):\n",
    "    subprocess.run(['chmod', '-R', '+w', job_dir])\n",
    "    subprocess.run(['rm', '-rf', job_dir])\n",
    "\n",
    "def excepthook(exctype, value, tb):\n",
    "    with status_lock:\n",
    "        update_status(status_csv, job_name, id, host, location, status='error', traceback=tb)\n",
    "    print('Type:', exctype)\n",
    "    print('Value:', value)\n",
    "    print('Traceback:', tb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGELOG.md\n",
      "code\n",
      "inputs\n",
      "outputs\n",
      "README.md\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='ls', returncode=0)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run('ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp, not_tmp_locations = get_locations(ephemeral_locations)\n",
    "\n",
    "# manage available disk space\n",
    "if req_disk_gb is None:\n",
    "    req_disk_gb = 0\n",
    "    \n",
    "with status_lock:\n",
    "    \n",
    "    found_location=False\n",
    "    \n",
    "    if tmp:\n",
    "        tmp = '/tmp'\n",
    "        available_disk = get_available_disk_resource(tmp, host, status_csv)\n",
    "        if req_disk_gb < available_disk:\n",
    "            found_location=True\n",
    "            location=tmp\n",
    "            \n",
    "    \n",
    "    elif not_tmp_locations and not found_location:\n",
    "        not_tmp_df = (\n",
    "            pd.DataFrame({'location':not_tmp_locations})\n",
    "            .assign(available_disk = lambda df_: \n",
    "                df_['location'].apply(lambda x_: get_available_disk_resource(x_, host, status_csv))\n",
    "                )\n",
    "            .sort_values('free_space', ascending=False)\n",
    "            )\n",
    "\n",
    "        if req_disk_gb < not_tmp_df['available_disk'].iat[0]:\n",
    "            found_location = True\n",
    "            location = not_tmp_df['location'].iat[0]\n",
    "            \n",
    "            \n",
    "    if found_location:\n",
    "        job_dir = str(Path(location) / f'job-{job_name}-{user}')\n",
    "        set_status(status_csv, job_name, job_id, req_disk_gb, host, location, job_dir, status='ongoing', start=datetime.today().strftime(\"%Y/%m/%d %H:%M:%S\"))\n",
    "    else:\n",
    "        set_status(status_csv, job_name, job_id, req_disk_gb, host, location, job_dir=None, status='no-space', start=datetime.today().strftime(\"%Y/%m/%d %H:%M:%S\"))\n",
    "        raise Exception(\"Coulnd't find a place with enough disk space.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clone_ria_prefix = re.search(r'ria\\+\\w+:\\/{2}', clone_target).group()\n",
    "    clone_target = clone_target.replace(clone_ria_prefix, '')\n",
    "except:\n",
    "    # assume ria requires a file protocol if no protocol in the job_config\n",
    "    clone_ria_prefix = 'ria+file://'\n",
    "try:\n",
    "    push_target = re.sub(r'ria\\+\\w+:\\/{2}', '', push_target)\n",
    "except:\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Attempting a clone into /tmp/job-test-ramirezd \n",
      "[INFO] Attempting to clone from file:///misc/geminis2/ramirezd/test_bet/.fairlybig/input_ria/f5d/b201b-6eed-46ee-8c97-b586f3f694e6 to /tmp/job-test-ramirezd \n",
      "[INFO] Completed clone attempts for Dataset(/tmp/job-test-ramirezd) \n",
      "[INFO] Reconfigured input_ria-storage for ria+file:///misc/geminis2/ramirezd/test_bet/.fairlybig/input_ria/ \n",
      "[INFO] Configure additional publication dependency on \"input_ria-storage\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configure-sibling(ok): . (sibling)\n",
      "install(ok): /tmp/job-test-ramirezd (dataset)\n",
      "action summary:\n",
      "  configure-sibling (ok: 1)\n",
      "  install (ok: 1)\n",
      "subdataset(ok): inputs/mri-raw (dataset)\n"
     ]
    }
   ],
   "source": [
    "super_clone_target = f'{clone_ria_prefix}{clone_target}#{super_ds_id}'\n",
    "\n",
    "dl.clone(source=super_clone_target, path=job_dir, git_clone_opts=['-c annex.private=true'])\n",
    "os.chdir(job_dir)\n",
    "\n",
    "push_path = str(Path(push_target) / Path(super_ds_id[:3]) / Path(super_ds_id[3:]))\n",
    "git_add_remote(push_path, 'cwd')\n",
    "\n",
    "ds = dl.Dataset(job_dir)\n",
    "sd = pd.DataFrame(ds.subdatasets())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_datasets is None:\n",
    "    output_datasets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_datasets and  (pd.Series(output_datasets).isin(sd['gitmodule_name']).all()):\n",
    "    raise Exception(\"Not all output datasets are found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output_dataset in output_datasets:\n",
    "    sd_id = sd.query(\"gitmodule_name == @output_dataset\")['gitmodule_datalad-id'].iat[0]\n",
    "    get_private_subdataset(clone_target, output_dataset, sd_id)\n",
    "    \n",
    "    push_path = str(Path(push_target) / Path(sd_id[:3]) / Path(sd_id[3:]))\n",
    "    git_add_remote(push_path, output_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switched to a new branch 'job-test'\n"
     ]
    }
   ],
   "source": [
    "# Checkout to job branch\n",
    "branch_name = f'job-{job_name}'\n",
    "\n",
    "for output_dataset in output_datasets:\n",
    "    do_checkout(output_dataset, branch_name)\n",
    "    \n",
    "do_checkout(branch_name, 'cwd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preget_inputs is None or None in preget_inputs:\n",
    "    preget_inputs = []\n",
    "for preget_input in preget_inputs:\n",
    "    dl.get(preget_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/misc/geminis2/ramirezd/fb_test',\n",
       " '/misc/geminis/ramirezd/miniconda3/envs/py-minis/lib/python311.zip',\n",
       " '/misc/geminis/ramirezd/miniconda3/envs/py-minis/lib/python3.11',\n",
       " '/misc/geminis/ramirezd/miniconda3/envs/py-minis/lib/python3.11/lib-dynload',\n",
       " '',\n",
       " '/misc/geminis/ramirezd/miniconda3/envs/py-minis/lib/python3.11/site-packages',\n",
       " '/home/inb/soporte/lanirem_software/apptainer/bin/apptainer',\n",
       " '/home/inb/soporte/lanirem_software/apptainer/bin/apptainer']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/inb/soporte/lanirem_software/apptainer/bin/apptainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/home/inb/soporte/lanirem_software/go_1.20.6/bin:/home/inb/soporte/lanirem_software/apptainer/bin:/opt/sge/bin:/opt/sge/bin/lx-amd64:/opt/sge/bin:/opt/sge/bin/lx-amd64:/home/inb/ramirezd/.local/bin:/home/inb/soporte/lanirem_software/ANTs_2.4.4/Scripts:/home/inb/soporte/lanirem_software/ANTs_2.4.4/bin:/home/inb/soporte/lanirem_software/fsl_6.0.7.4/share/fsl/bin:/misc/geminis/ramirezd/miniconda3/envs/py-minis/bin:/misc/geminis/ramirezd/miniconda3/condabin:/opt/sge/bin:/opt/sge/bin/lx-amd64:/home/inb/soporte/inb_tools:/home/inb/ramirezd/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin:/misc/geminis2/hcp_workbench/bin_linux64:/misc/geminis2/hcp_workbench/bin_linux64:/misc/geminis2/hcp_workbench/bin_linux64\n"
     ]
    }
   ],
   "source": [
    "%set_env PATH=/home/inb/soporte/lanirem_software/go_1.20.6/bin:/home/inb/soporte/lanirem_software/apptainer/bin:/opt/sge/bin:/opt/sge/bin/lx-amd64:/opt/sge/bin:/opt/sge/bin/lx-amd64:/home/inb/ramirezd/.local/bin:/home/inb/soporte/lanirem_software/ANTs_2.4.4/Scripts:/home/inb/soporte/lanirem_software/ANTs_2.4.4/bin:/home/inb/soporte/lanirem_software/fsl_6.0.7.4/share/fsl/bin:/misc/geminis/ramirezd/miniconda3/envs/py-minis/bin:/misc/geminis/ramirezd/miniconda3/condabin:/opt/sge/bin:/opt/sge/bin/lx-amd64:/home/inb/soporte/inb_tools:/home/inb/ramirezd/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin:/misc/geminis2/hcp_workbench/bin_linux64:/misc/geminis2/hcp_workbench/bin_linux64:/misc/geminis2/hcp_workbench/bin_linux64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs/sub-001A_T1w_bet.nii.gz'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Making sure inputs are available (this may take some time) \n",
      "[INFO] == Command start (output follows) ===== \n",
      "[INFO] == Command exit (modification check follows) ===== \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run(ok): /tmp/job-test-ramirezd (dataset) [apptainer run -e .datalad/environments/f...]\n",
      "add(ok): outputs/sub-001A_T1w_bet.nii.gz (file)\n",
      "save(ok): . (dataset)\n",
      "action summary:\n",
      "  add (ok: 1)\n",
      "  get (notneeded: 3)\n",
      "  run (ok: 1)\n",
      "  save (notneeded: 1, ok: 1)\n"
     ]
    }
   ],
   "source": [
    "if message is None:\n",
    "    message = branch_name\n",
    "\n",
    "if commit:\n",
    "    dl.rerun(\n",
    "        revision=commit,\n",
    "        explicit=is_explicit\n",
    "    )\n",
    "    \n",
    "elif container:\n",
    "    dl.containers_run(\n",
    "        dl_cmd,\n",
    "        container_name=container,\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "        message=message,\n",
    "        explicit=is_explicit\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    dl.run(\n",
    "        dl_cmd,\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "        message=message,\n",
    "        explicit=is_explicit\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Determine push target \n",
      "[INFO] Push refspecs \n",
      "[INFO] Transfer data \n",
      "[INFO] Finished push of Dataset(/tmp/job-test-ramirezd) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action summary:\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To /misc/geminis2/ramirezd/test_bet/.fairlybig/output_ria/f5d/b201b-6eed-46ee-8c97-b586f3f694e6\n",
      " * [new branch]      job-test -> job-test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# push annex data\n",
    "dl.push(\n",
    "    path='.',\n",
    "    to='output_ria-storage',\n",
    ")\n",
    "\n",
    "for output_dataset in output_datasets:\n",
    "    dl.push(\n",
    "        path=output_dataset,\n",
    "        to='output_ria-storage',\n",
    "    )\n",
    "    \n",
    "# push git data\n",
    "with push_lock:\n",
    "    git_push('cwd')\n",
    "    for output_dataset in output_datasets:\n",
    "        git_push(output_dataset)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/job-test-ramirezd'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1172810/2305348307.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mstatus_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     update_status(status_csv, \n\u001b[0m\u001b[1;32m      6\u001b[0m                     \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1172810/61514119.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(status_csv, job_name, id, host, location, status, update, traceback)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mstatus_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     is_job = (\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mstatus_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'job_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mstatus_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mstatus_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'host'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mstatus_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/geminis/ramirezd/miniconda3/envs/py-minis/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1464\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1467\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "cleanup(job_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1172810/3156608850.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mstatus_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     update_status(status_csv, \n\u001b[0m\u001b[1;32m      4\u001b[0m                     \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1172810/61514119.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(status_csv, job_name, id, host, location, status, update, traceback)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mstatus_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     is_job = (\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mstatus_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'job_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mstatus_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mstatus_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'host'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mstatus_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/geminis/ramirezd/miniconda3/envs/py-minis/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1464\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1467\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "with status_lock:\n",
    "    \n",
    "    update_status(status_csv, \n",
    "                    job_name, \n",
    "                    job_id, \n",
    "                    host, \n",
    "                    location, \n",
    "                    status='completed', \n",
    "                    update=datetime.today().strftime(\"%Y/%m/%d %H:%M:%S\"), \n",
    "                    traceback=None\n",
    "                    )\n",
    "\n",
    "print(\"Job completed succesfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-minis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b7ca23d180daa64c5df23970c68613774f6face07a17b610016dc57dc2566e45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
